{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# DAG with Estimator\n\nFlowsheet can be used to apply an estimator in a process flowsheet.  This example demonstrates how to use a DAG\nto define a flowsheet that applies a lump estimator to a feed stream.\n\nThe focus will not be on the model development, but rather on the simulation.  The model is a simple RandomForest\nregressor that predicts the lump mass and composition from the feed stream.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This example uses the `estimator` extras.  ensure you have installed like ``poetry install -E estimator``.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\n\n# This import at the top to guard against the estimator extras not being installed\nfrom elphick.mass_composition.utils.sklearn import PandasPipeline\n\nimport pandas as pd\nimport plotly\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nfrom elphick.mass_composition import MassComposition, Stream\nfrom elphick.mass_composition.dag import DAG\nfrom elphick.mass_composition.datasets.sample_data import iron_ore_met_sample_data\nfrom elphick.mass_composition.flowsheet import Flowsheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n\nWe load some metallurgical data from a drill program, REF: A072391\nSince we are not concerned about the model performance in this example, we'll convert the categorical feature\nbulk_hole_no to an integer\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df: pd.DataFrame = iron_ore_met_sample_data()\n\nbase_components = ['fe', 'p', 'sio2', 'al2o3', 'loi']\ncols_x = ['dry_weight_lump_kg'] + [f'head_{comp}' for comp in base_components] + ['bulk_hole_no']\ncols_y = ['lump_pct'] + [f'lump_{comp}' for comp in base_components]\n\ndf = df.loc[:, cols_x + cols_y].query('lump_pct>0').dropna(how='any')\ndf = df.rename(columns={'dry_weight_lump_kg': 'head_mass_dry'})\ndf['bulk_hole_no'] = df['bulk_hole_no'].astype('category').cat.codes\n\nlogger.info(df.shape)\ndf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build a model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X: pd.DataFrame = df[[col for col in df.columns if col not in cols_y]]\ny: pd.DataFrame = df[cols_y]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model needs to be wrapped in a PandasPipeline object to ensure that the column names are preserved.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipe: PandasPipeline = PandasPipeline.from_pipeline(\n    make_pipeline(StandardScaler(), RandomForestRegressor(n_estimators=100, random_state=42)))\n\npipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the model\nThe model can be called directly to predict the lump percentage and composition from the feed stream.\nWe will pass in a dataframe with the same columns as the training data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_pred = pipe.fit(X_train.drop(columns=['head_mass_dry']), y_train).predict(X_test)\nlogger.info(f'Test score: {pipe.score(X_test, y_test)}')\ny_pred.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Head MassComposition object\nNow we will create a MassComposition object and use it to apply the model to the feed stream.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "head: MassComposition = MassComposition(data=X_test.drop(columns=['bulk_hole_no']), name='head',\n                                        mass_dry_var='head_mass_dry')\nlump, fines = head.split_by_estimator(estimator=pipe, name_2='fines',\n                                      mass_recovery_column='lump_pct', mass_recovery_max=100,\n                                      extra_features=X_test['bulk_hole_no'])\nlump.data.to_dataframe().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fines.data.to_dataframe().head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the DAG\n\nFirst we define a simple DAG, where the feed stream is split into two streams, lump and fines.\nThe lump estimator requires the usual mass-composition variables plus an addition feature/variable\ncalled `bulk_hole_no`. Since the `bulk_hole_no` is available in the feed stream, it is immediately accessible\nto the estimator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "head: MassComposition = MassComposition(data=X_test, name='head',\n                                        mass_dry_var='head_mass_dry')\n\ndag = DAG(name='A072391', n_jobs=1)\ndag.add_input(name='head')\ndag.add_step(name='screen', operation=Stream.split_by_estimator, streams=['head'],\n             kwargs={'estimator': pipe, 'name_1': 'lump', 'name_2': 'fines',\n                     'mass_recovery_column': 'lump_pct', 'mass_recovery_max': 100})\ndag.add_output(name='lump', stream='lump')\ndag.add_output(name='fines', stream='fines')\ndag.run(input_streams={'head': head}, progress_bar=True)\n\nfig = Flowsheet.from_dag(dag).plot_network()\nfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## More Complex DAG\nThis DAG is to test a more complex flowsheet where the estimator may have all the features\nimmediately available in the parent stream.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This example works, but it does so since all attribute (extra) variables are passed all the way around\n   the network in the current design.  This is to be changed in the future to allow for more efficient processing.\n   Once attributes are no longer passed, changes will be needed to the DAG to marshall\n   features from other streams in the network (most often the input stream).</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dag = DAG(name='A072391', n_jobs=1)\ndag.add_input(name='head')\ndag.add_step(name='screen', operation=Stream.split_by_estimator, streams=['head'],\n             kwargs={'estimator': pipe, 'name_1': 'lump', 'name_2': 'fines',\n                     'mass_recovery_column': 'lump_pct', 'mass_recovery_max': 100})\ndag.add_step(name='screen_2', operation=Stream.split_by_estimator, streams=['fines'],\n             kwargs={'estimator': pipe, 'name_1': 'lump_2', 'name_2': 'fines_2',\n                     'mass_recovery_column': 'lump_pct', 'mass_recovery_max': 100,\n                     'allow_prefix_mismatch': True})\ndag.add_output(name='lump', stream='lump_2')\ndag.add_output(name='fines', stream='fines_2')\ndag.add_output(name='stockpile', stream='lump')\ndag.run(input_streams={'head': head}, progress_bar=True)\n\nfs: Flowsheet = Flowsheet.from_dag(dag)\n\nfig = fs.plot_network()\nfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = fs.table_plot(plot_type='sankey', sankey_color_var='Fe', sankey_edge_colormap='copper_r', sankey_vmin=52,\n                    sankey_vmax=70)\nplotly.io.show(fig)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}